{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2VR5yE2Q1lD"
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "In this Assignment, we will be exploring how to preprocess tweets for sentiment analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Try8QG5xQ1lL"
   },
   "outputs": [],
   "source": [
    "import nltk                                # Python library for NLP\n",
    "from nltk.corpus import twitter_samples    # sample Twitter dataset from NLTK\n",
    "import matplotlib.pyplot as plt            # library for visualization\n",
    "import random                              # pseudo-random number generator\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "puelnnDoQ1lM"
   },
   "source": [
    "## About the Twitter dataset\n",
    "\n",
    "The sample dataset from NLTK is separated into positive and negative tweets. It contains 5000 positive tweets and 5000 negative tweets exactly. The exact match between these classes is not a coincidence. The intention is to have a balanced dataset. That does not reflect the real distributions of positive and negative classes in live Twitter streams.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this mean?\n",
    "\n",
    "In the NLTK sample dataset you mentioned, there are 5000 positive tweets and 5000 negative tweets. This equal distribution of positive and negative tweets is intentional and serves the purpose of creating a balanced dataset for training and evaluation.\n",
    "\n",
    "However, it's important to note that this balanced dataset does not accurately reflect the real distribution of positive and negative tweets in live Twitter streams. In real-time, the occurrence of positive and negative tweets can vary significantly based on several factors.\n",
    "\n",
    "In real-world scenarios, it's common to observe imbalanced distributions of positive and negative tweets. This imbalance presents challenges when training and evaluating machine learning models that have been trained on a balanced dataset. The models may not generalize well to imbalanced distributions and may exhibit biases or limitations when applied to real-time Twitter streams.\n",
    "\n",
    "To address such challenges, specialized techniques for handling imbalanced data can be employed, such as oversampling the minority class, undersampling the majority class, or using advanced algorithms that handle imbalanced data effectively. Additionally, incorporating contextual information, topic modeling, or sentiment analysis techniques can further improve the understanding and analysis of sentiment in live Twitter streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zxKktlhMQ1lN",
    "outputId": "59b74f23-525c-425d-9e5e-1622369751dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\Sanjay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloads sample twitter dataset.\n",
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjWs6tqbQ1lN"
   },
   "source": [
    "We can load the text fields of the positive and negative tweets by using the module's `strings()` method like this:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line assigns the variable all_positive_tweets to a list of strings representing the positive tweets from the NLTK Twitter sample dataset. The `twitter_samples.strings()` function is used to retrieve the tweets, and `positive_tweets.json` is passed as the argument to specify the file containing the positive tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cCN9YKaCQ1lN"
   },
   "outputs": [],
   "source": [
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rfK_KjdIQ1lO"
   },
   "source": [
    "Next, we'll print a report with the number of positive and negative tweets. It is also essential to know the data structure of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XrygbufQ1lO",
    "outputId": "14653392-3031-421b-b3d5-8d33dab48fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive tweets:  5000\n",
      "Number of negative tweets:  5000\n",
      "\n",
      "The type of all_positive_tweets is:  <class 'list'>\n",
      "The type of a tweet entry is:  <class 'str'>\n",
      "hopeless for tmr :(\n"
     ]
    }
   ],
   "source": [
    "print('Number of positive tweets: ', len(all_positive_tweets))\n",
    "print('Number of negative tweets: ', len(all_negative_tweets))\n",
    "\n",
    "print('\\nThe type of all_positive_tweets is: ', type(all_positive_tweets))\n",
    "print('The type of a tweet entry is: ', type(all_negative_tweets[0]))\n",
    "print(all_negative_tweets[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9SEd0krQ1lP"
   },
   "source": [
    "## Looking at raw texts\n",
    "\n",
    "\n",
    "\n",
    "Below, you will print one random positive and one random negative tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x_4GnNOMQ1lP",
    "outputId": "c1203925-e445-4771-b41d-9c4e961fe02f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imran khan a hero :) really  #IKPrideOfPak\n",
      "\n",
      "@QjQj_Kwon How weird :( ^^\n"
     ]
    }
   ],
   "source": [
    "print(all_positive_tweets[random.randint(0,5000)])\n",
    "print()\n",
    "print(all_negative_tweets[random.randint(0,5000)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VlhrXoUrQ1lQ"
   },
   "source": [
    "## Preprocess raw text for Sentiment analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "a3lDAfnMQ1lQ"
   },
   "source": [
    "Data preprocessing is one of the critical steps in any machine learning project. It includes cleaning and formatting the data before feeding into a machine learning algorithm. For NLP, the preprocessing steps are comprised of the following tasks:\n",
    "\n",
    "* Tokenizing the string\n",
    "* Lowercasing\n",
    "* Removing stop words and punctuation\n",
    "* Stemming\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Br..eak it down!\n",
    "Example Sentence: \"I love eating pizza! It's delicious.\"\n",
    "\n",
    "Tokenizing the String:\n",
    "Tokenization involves splitting the sentence into individual tokens or words. In this case, the tokenized version of the sentence would be: `[\"I\", \"love\", \"eating\", \"pizza\", \"!\", \"It's\", \"delicious\", \".\"]`\n",
    "\n",
    "Lowercasing:\n",
    "Lowercasing involves converting all the tokens to lowercase. After lowercasing, the tokenized sentence becomes: `[\"i\", \"love\", \"eating\", \"pizza\", \"!\", \"it's\", \"delicious\", \".\"]`\n",
    "\n",
    "Removing Stop Words and Punctuation:\n",
    "Stop words are common words like \"I,\" \"it's,\" and \"the\" that don't carry significant meaning for analysis. Punctuation marks, such as \"!\" and \".\", are also removed. After removing stop words and punctuation, the tokenized and lowercased sentence becomes: `[\"love\", \"eating\", \"pizza\", \"delicious\"]`\n",
    "\n",
    "Stemming:\n",
    "Stemming reduces words to their base or root form. In this case, stemming the sentence using the Porter stemming algorithm would result in: `[\"love\", \"eat\", \"pizza\", \"delici\"]`\n",
    "\n",
    "So, after applying all the preprocessing steps, the example sentence has been transformed into the following tokens: `[\"love\", \"eat\", \"pizza\", \"delici\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bm6bNsrzQ1lQ",
    "outputId": "95fed2a5-2bba-4c9b-c9f1-beee7a5ed5e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday offâ€¦ https://t.co/3tfYom0N1i\n"
     ]
    }
   ],
   "source": [
    "# Our selected sample. Complex enough to exemplify each step\n",
    "tweet = all_positive_tweets[2277]\n",
    "print(tweet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YyZR0yYwQ1lQ"
   },
   "source": [
    "Let's import a few more libraries for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tcviT9auQ1lR",
    "outputId": "3f62c21b-9c43-4487-ba0d-f64ba264d7de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sanjay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download the stopwords from NLTK\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aT8QHMY5Q1lR"
   },
   "outputs": [],
   "source": [
    "import re                                  # library for regular expression operations\n",
    "import string                              # for string operations\n",
    "\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer        # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VG3ImX_IQ1lR"
   },
   "source": [
    "### Remove hyperlinks,  Twitter marks and styles\n",
    "\n",
    "Since we have a Twitter dataset, we'd like to remove some substrings commonly used on the platform like the hashtag, retweet marks, and hyperlinks. We'll use the [re](https://docs.python.org/3/library/re.html) library to perform regular expression operations on our tweet. We'll define our search pattern and use the `sub()` method to remove matches by substituting with an empty character (i.e. `''`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "a5IcXDqkQ1lR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My beautiful sunflowers on a sunny Friday morning off :) sunflowers favourites happy Friday offâ€¦ \n"
     ]
    }
   ],
   "source": [
    "        # remove old style retweet text \"RT\"\n",
    "tweet2 = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "\n",
    "# remove hyperlinks\n",
    "tweet2 = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet2)\n",
    "\n",
    "# remove hashtags\n",
    "# only removing the hash # sign from the word\n",
    "tweet2 = re.sub(r'#', '', tweet2)\n",
    "\n",
    "print(tweet2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bruhtal\n",
    "\n",
    "#### Firstly let's see `^RT[\\s]+`\n",
    "\n",
    "`^`: The caret symbol at the beginning of the pattern signifies that the match should start at the beginning of the string.\n",
    "\n",
    "`RT`: This matches the characters \"RT\" exactly as they appear.\n",
    "\n",
    "`[\\s]+`: The square brackets indicate a character set or class. \\s is a shorthand character class that represents whitespace characters, such as spaces, tabs, and newlines. The + quantifier specifies that one or more whitespace characters should be matched.\n",
    "\n",
    "Putting it all together, `^RT[\\s]+` matches a string that starts with the characters \"RT\" followed by one or more whitespace characters.\n",
    "\n",
    "Example:\n",
    "Suppose we have a tweet: \"RT @username: This is a sample tweet.\"\n",
    "\n",
    "Applying the re.sub() function with the pattern `^RT[\\s]+`, we would get the following result:\n",
    "\n",
    "Original tweet: \"RT @username: This is a sample tweet.\"\n",
    "Modified tweet: \"@username: This is a sample tweet.\"\n",
    "\n",
    "#### Let's see `'https?://[^\\s\\n\\r]+'`\n",
    "\n",
    "`r`: The \"r\" at the beginning of the pattern indicates that it is a raw string, allowing backslashes to be treated as literal characters instead of escape characters.\n",
    "\n",
    "`https?://`: This part matches the literal characters \"http://\" or \"https://\". The question mark `\"?\" makes the \"s\" optional, allowing for both \"http://\" and \"https://\" to be matched.`\n",
    "\n",
    "`[^\\s\\n\\r]+`: This part is a character class that matches any character that is not a whitespace character, newline character, or carriage return character. The caret `\"^\"` at the beginning of the character class negates the match, so it matches any character not listed. The `\"+\"` quantifier after the character class matches one or more occurrences of the preceding pattern.\n",
    "\n",
    "To summarize, the pattern r'https?://[^\\s\\n\\r]+' matches URLs starting with \"http://\" or \"https://\" and followed by one or more characters that are not whitespace, newline, or carriage return characters.\n",
    "\n",
    "Example:\n",
    "Suppose we have a tweet: \"Check out this link: https://example.com\"\n",
    "\n",
    "Applying the regular expression pattern r'https?://[^\\s\\n\\r]+', we would get the following result:\n",
    "\n",
    "Original tweet: \"Check out this link: https://example.com\"\n",
    "Matched URL: \"https://example.com\"\n",
    "In this example, the pattern r'https?://[^\\s\\n\\r]+' matches the URL \"https://example.com\" in the tweet. It captures the entire URL because it starts with \"https://\" and consists of characters that are not whitespace, newline, or carriage return. This pattern is useful for removing or replacing URLs in text data.\n",
    "\n",
    "#### And the now easy-peasy `r'#'`\n",
    "\n",
    "This line removes hashtags from the tweet by replacing the hash sign \"#\" with an empty string. It removes the hash symbol but retains the word itself.\n",
    "\n",
    "\n",
    "This code snippet demonstrates how to use regular expressions (re.sub()) in Python to remove specific patterns such as old-style retweet text, hyperlinks, and hashtags from a given tweet. The resulting tweet2 will be a modified version of the original tweet with the specified patterns removed.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pHn6jA0tQ1lR"
   },
   "source": [
    "### Tokenize the string\n",
    "\n",
    "To tokenize means to split the strings into individual words without blanks or tabs. In this same step, we will also convert each word in the string to lower case. The [tokenize](https://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.casual) module from NLTK allows us to do these easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TzLGfUX3Q1lS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenized string:\n",
      "['my', 'beautiful', 'sunflowers', 'on', 'a', 'sunny', 'friday', 'morning', 'off', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'off', 'â€¦']\n"
     ]
    }
   ],
   "source": [
    "# instantiate tokenizer class\n",
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "\n",
    "# tokenize tweets\n",
    "tweet_tokens = tokenizer.tokenize(tweet2)\n",
    "\n",
    "print()\n",
    "print('Tokenized string:')\n",
    "print(tweet_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-R-E-A-K-!\n",
    "\n",
    "`tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)`\n",
    "\n",
    "This line instantiates the TweetTokenizer class with three parameters:\n",
    "\n",
    "`preserve_case=False` specifies that the tokenizer should convert all tokens to lowercase.\n",
    "`strip_handles=True` indicates that user handles (e.g., @username) should be removed from the tokens.\n",
    "`reduce_len=True` specifies that repeated character sequences of length 3 or more should be reduced to length 3.\n",
    "\n",
    "More on `reduce_len=True`:\n",
    "\n",
    "In some informal text, especially in tweets, people often use elongated words with repeated characters to convey emphasis or emotion. For example, \"soooo\" instead of \"so\" or \"happyyyy\" instead of \"happy.\"\n",
    "\n",
    "Setting reduce_len=True in TweetTokenizer specifies that repeated character sequences of length 3 or more should be reduced to length 3. This feature helps in normalizing such elongated words to their base form by truncating the repeated characters beyond three.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tzhpto5LQ1lS"
   },
   "source": [
    "### Remove stop words and punctuations\n",
    "\n",
    "The next step is to remove stop words and punctuation. Stop words are words that don't add significant meaning to the text. You'll see the list provided by NLTK when you run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hEuUul5rQ1lS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words\n",
      "\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "\n",
      "Punctuation\n",
      "\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "#Import the english stop words list from NLTK\n",
    "stopwords_english = stopwords.words('english') \n",
    "\n",
    "print('Stop words\\n')\n",
    "print(stopwords_english)\n",
    "\n",
    "print('\\nPunctuation\\n')\n",
    "print(string.punctuation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CgLmDiBNQ1lS"
   },
   "source": [
    "We can see that the stop words list above contains some words that could be important in some contexts. \n",
    "\n",
    "\n",
    "Time to clean up our tokenized tweet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HNhIlrG1Q1lT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'beautiful', 'sunflowers', 'on', 'a', 'sunny', 'friday', 'morning', 'off', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'off', 'â€¦']\n",
      "removed stop words and punctuation:\n",
      "['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'â€¦']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tweet_tokens)\n",
    "\n",
    "tweets_clean = []\n",
    "\n",
    "for word in tweet_tokens: # Go through every word in your tokens list\n",
    "    if (word not in stopwords_english and  # remove stopwords\n",
    "        word not in string.punctuation):  # remove punctuation\n",
    "        tweets_clean.append(word)\n",
    "\n",
    "print('removed stop words and punctuation:')\n",
    "print(tweets_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Lu-m6zZwQ1lT"
   },
   "source": [
    "Please note that the words **happy** and **sunny** in this list are correctly spelled. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aYU0Fo6vQ1lT"
   },
   "source": [
    "### Stemming\n",
    "\n",
    "Stemming is the process of converting a word to its most general form, or stem. This helps in reducing the size of our vocabulary.\n",
    "\n",
    "Consider the words: \n",
    " * **learn**\n",
    " * **learn**ing\n",
    " * **learn**ed\n",
    " * **learn**t\n",
    " \n",
    "All these words are stemmed from its common root **learn**. However, in some cases, the stemming process produces words that are not correct spellings of the root word. For example, **happi** and **sunni**. That's because it chooses the most common stem for related words. For example, we can look at the set of words that comprises the different forms of happy:\n",
    "\n",
    " * **happ**y\n",
    " * **happi**ness\n",
    " * **happi**er\n",
    " \n",
    "We can see that the prefix **happi** is more commonly used. We cannot choose **happ** because it is the stem of unrelated words like **happen**.\n",
    " \n",
    "NLTK has different modules for stemming and we will be using the [PorterStemmer](https://www.nltk.org/api/nltk.stem.html#module-nltk.stem.porter) module which uses the [Porter Stemming Algorithm](https://tartarus.org/martin/PorterStemmer/). Let's see how we can use it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dPUI2hi3Q1lT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'â€¦']\n",
      "stemmed words:\n",
      "['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', 'â€¦']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tweets_clean)\n",
    "\n",
    "# Instantiate stemming class\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "# Create an empty list to store the stems\n",
    "tweets_stem = [] \n",
    "\n",
    "for word in tweets_clean:\n",
    "    stem_word = stemmer.stem(word)  # stemming word\n",
    "    tweets_stem.append(stem_word)  # append to the list\n",
    "\n",
    "print('stemmed words:')\n",
    "print(tweets_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-NlATHQ8z2Cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beauti sunflow sunni friday morn :) sunflow favourit happi friday â€¦'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_tweet=' '.join(tweets_stem)\n",
    "processed_tweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "kXevPC2RQ1lU"
   },
   "source": [
    "That's it! Now we have a sentence which can be feed into to the next stage \n",
    "of our  project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zBHp8KB83xz1"
   },
   "source": [
    "."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wlUUC5S33jMQ"
   },
   "source": [
    "PART 2: Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Ifa_z4zG3MH_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\Sanjay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "nltk.download('twitter_samples')\n",
    "# select the lists of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "# concatenate the lists, 1st part is the positive tweets followed by the negative\n",
    "tweets = all_positive_tweets + all_negative_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "P1qocwU-A_UO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Since models own stopped stocking at boots I can't get any and I can't even order online because it's telling me it's unsafe :(\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    #print tweets here\n",
    "tweets[np.random.randint(0,10001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VRQ9PKcs6gAy"
   },
   "outputs": [],
   "source": [
    "y=np.zeros(10000)\n",
    "for i in range(5000):\n",
    "  y[i]=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "u28Un7Yc2w0x"
   },
   "source": [
    "Now make a function and implement pre-processing into all tweets and then make an array that contains all processed tweets as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokeniser(tweet):\n",
    "    tweet_tokens=[]\n",
    "    tweet_clean=[]\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    \n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "    tweets_clean = [word for word in tweet_tokens if word not in stopwords_english and word not in string.punctuation]\n",
    "    \n",
    "\n",
    "    return tweets_clean\n",
    "def stemming(tweets_clean):\n",
    "    stemmer=PorterStemmer()\n",
    "    tweets_stem=[]\n",
    "    tweets_stem = [stemmer.stem(word) for word in tweets_clean]\n",
    "    return ' '.join(tweets_clean)    \n",
    "def format_tweeets(tweet_list):\n",
    "    processed_tweets=[]\n",
    "    with tqdm(total=len(tweet_list), desc=\"Processing\") as pbar:\n",
    "        for tweet in tweet_list:\n",
    "            tweet =re.sub(r'^RT[\\s]+', '', tweet)\n",
    "            tweet=re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
    "            tweet = re.sub(r'#', '', tweet)\n",
    "            processed_tweets.append(stemming(tokeniser(tweet)))\n",
    "            pbar.update(1)\n",
    "    return processed_tweets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "HLvmNbV_3W1z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:05<00:00, 1915.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "nptweets=np.array(tweets)\n",
    "formatted_tweets=format_tweeets(nptweets)\n",
    "# formatted_tweets=[]\n",
    "# i=0\n",
    "\n",
    "# for tweet in nptweets:\n",
    "#     tweet =re.sub(r'^RT[\\s]+', '', tweet)\n",
    "#     tweet=re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
    "#     tweet = re.sub(r'#', '', t weet)\n",
    "#     formatted_tweets.append(stemming(tokeniser(tweet)))\n",
    "#     i+=1\n",
    "#     print_and_clear(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "\n",
      "\n",
      "['followfriday top engaged members community week :)', 'hey james odd :/ please call contact centre 02392441234 able assist :) many thanks']\n"
     ]
    }
   ],
   "source": [
    "print(type(tweets))\n",
    "print()\n",
    "print()\n",
    "print(formatted_tweets[:2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zDYnvp9u4Rn3"
   },
   "source": [
    "Now use **TfidfVectorizer** to vectorize your tweets into a numbered matrix \n",
    " **X**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is `TfidVectorizer`?\n",
    "\n",
    "**TF-IDF**: TF-IDF is a way to measure the importance of words in a document. It considers two factors:\n",
    "\n",
    "**Term Frequency (TF)**: How often a word appears in a document.\n",
    "**Inverse Document Frequency (IDF)**: How common or rare a word is across all documents.\n",
    "TF-IDF gives higher weight to words that appear frequently in a document but less frequently in the entire collection of documents. This helps to highlight important words that are unique to specific documents.\n",
    "\n",
    "**Vectorization**: TfidfVectorizer converts text documents into numbers, allowing us to perform calculations and analysis on the text. It represents each document as a numerical vector. The vector contains information about the importance of different words in the document.\n",
    "\n",
    "**Feature Extraction**: TfidfVectorizer performs preprocessing on text documents. It breaks down the text into individual words, converts them to lowercase, and removes unnecessary words like \"the\" or \"and\". It also considers sequences of words (n-grams) to capture more contextual information.\n",
    "\n",
    "Parameters: TfidfVectorizer has options to customize its behavior. For example:\n",
    "\n",
    "**max_features** limits the number of words (features) used in the vectorization process.\n",
    "**ngram_range** determines the size of word sequences to consider (e.g., single words, pairs of words, etc.).\n",
    "**stop_words** specifies a list of common words to ignore during vectorization.\n",
    "**use_idf** controls whether IDF weighting is applied.\n",
    "**Fit and Transform**: To use TfidfVectorizer, you first fit it on your training data to learn the vocabulary and calculate the TF-IDF values. Then, you can transform new documents using the same vectorizer, ensuring consistent representation across different datasets.\n",
    "\n",
    "In simpler terms, TfidfVectorizer helps convert text documents into meaningful numerical representations. It considers word importance based on frequency and rarity, and it allows you to customize its behavior. By fitting and transforming the data, you can use the resulting numerical matrix for various analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "hG2SOoi83bTd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11911</th>\n",
       "      <th>11912</th>\n",
       "      <th>11913</th>\n",
       "      <th>11914</th>\n",
       "      <th>11915</th>\n",
       "      <th>11916</th>\n",
       "      <th>11917</th>\n",
       "      <th>11918</th>\n",
       "      <th>11919</th>\n",
       "      <th>11920</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11921 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3      4      5      6      7      8      9      \\\n",
       "0       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "9995    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "9996    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "9997    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "9998    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "9999    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      ...  11911  11912  11913  11914  11915  11916  11917  11918  11919  \\\n",
       "0     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "9995  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "9996  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "9997  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "9998  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "9999  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      11920  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "9995    0.0  \n",
       "9996    0.0  \n",
       "9997    0.0  \n",
       "9998    0.0  \n",
       "9999    0.0  \n",
       "\n",
       "[10000 rows x 11921 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "vectoriser = TfidfVectorizer()\n",
    "X = vectoriser.fit_transform(formatted_tweets)\n",
    "X_sparse=X.toarray()\n",
    "df=pd.DataFrame(X_sparse)\n",
    "print(X_sparse)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WyO-tSZl7n4_"
   },
   "source": [
    "Now you have a matrix **X** and **y** implement a model to classify this tweets.\n",
    "\n",
    "Note: \n",
    "\n",
    "1) You can use sequential models with tensorflow in which use 2 nodes in last layer.\n",
    "\n",
    "2) The node which has a higher value while using *model.predict* corresponds to the output.\n",
    "\n",
    "3) Use **SparseCategoricalCrossentropy** as a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "iyha1mVG7fgh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sparse, y, test_size=0.2, random_state=1234)\n",
    "dataset = df = pd.DataFrame(X_sparse)\n",
    "\n",
    "train_dataset = pd.DataFrame(X_train)\n",
    "train_dataset['Output']=y_train\n",
    "train_dataset_labels = train_dataset.pop('Output')\n",
    "test_dataset = pd.DataFrame(X_test)\n",
    "test_dataset['Output'] = y_test\n",
    "test_dataset_labels = test_dataset.pop('Output')\n",
    "dataset['Output'] = y\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 11921)\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11911</th>\n",
       "      <th>11912</th>\n",
       "      <th>11913</th>\n",
       "      <th>11914</th>\n",
       "      <th>11915</th>\n",
       "      <th>11916</th>\n",
       "      <th>11917</th>\n",
       "      <th>11918</th>\n",
       "      <th>11919</th>\n",
       "      <th>11920</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows Ã— 11921 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3      4      5      6      7      8      9      \\\n",
       "0       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "7995    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7996    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7997    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7998    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7999    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      ...  11911  11912  11913  11914  11915  11916  11917  11918  11919  \\\n",
       "0     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "7995  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7996  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7997  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7998  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7999  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      11920  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "7995    0.0  \n",
       "7996    0.0  \n",
       "7997    0.0  \n",
       "7998    0.0  \n",
       "7999    0.0  \n",
       "\n",
       "[8000 rows x 11921 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 11921)            0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                119220    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,242\n",
      "Trainable params: 119,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "normaliser = tf.keras.layers.Normalization(axis=-1,mean=0,variance=1)\n",
    "model = tf.keras.Sequential([normaliser,tf.keras.layers.Dense(units=10,activation='tanh'),\n",
    "                            tf.keras.layers.Dense(units=2,activation='softmax')])\n",
    "model.build(input_shape=(None, 11921))\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "225/225 [==============================] - 4s 13ms/step - loss: 0.6915 - accuracy: 0.5432 - val_loss: 0.6907 - val_accuracy: 0.5587\n",
      "Epoch 2/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.6890 - accuracy: 0.5940 - val_loss: 0.6886 - val_accuracy: 0.6025\n",
      "Epoch 3/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.6866 - accuracy: 0.6304 - val_loss: 0.6864 - val_accuracy: 0.6187\n",
      "Epoch 4/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.6841 - accuracy: 0.6413 - val_loss: 0.6843 - val_accuracy: 0.6288\n",
      "Epoch 5/50\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.6815 - accuracy: 0.6675 - val_loss: 0.6822 - val_accuracy: 0.6500\n",
      "Epoch 6/50\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.6790 - accuracy: 0.6903 - val_loss: 0.6799 - val_accuracy: 0.6662\n",
      "Epoch 7/50\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.6764 - accuracy: 0.6944 - val_loss: 0.6774 - val_accuracy: 0.6737\n",
      "Epoch 8/50\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.6735 - accuracy: 0.7153 - val_loss: 0.6752 - val_accuracy: 0.6612\n",
      "Epoch 9/50\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.6705 - accuracy: 0.6808 - val_loss: 0.6725 - val_accuracy: 0.6562\n",
      "Epoch 10/50\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.6675 - accuracy: 0.7056 - val_loss: 0.6698 - val_accuracy: 0.6562\n",
      "Epoch 11/50\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.6644 - accuracy: 0.7164 - val_loss: 0.6670 - val_accuracy: 0.6913\n",
      "Epoch 12/50\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.6611 - accuracy: 0.7351 - val_loss: 0.6644 - val_accuracy: 0.6662\n",
      "Epoch 13/50\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.6577 - accuracy: 0.7244 - val_loss: 0.6609 - val_accuracy: 0.7113\n",
      "Epoch 14/50\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.6540 - accuracy: 0.7437 - val_loss: 0.6577 - val_accuracy: 0.7050\n",
      "Epoch 15/50\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.6502 - accuracy: 0.7387 - val_loss: 0.6544 - val_accuracy: 0.7138\n",
      "Epoch 16/50\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.6463 - accuracy: 0.7489 - val_loss: 0.6509 - val_accuracy: 0.7138\n",
      "Epoch 17/50\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.6421 - accuracy: 0.7444 - val_loss: 0.6475 - val_accuracy: 0.7000\n",
      "Epoch 18/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.6379 - accuracy: 0.7553 - val_loss: 0.6438 - val_accuracy: 0.7025\n",
      "Epoch 19/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.6335 - accuracy: 0.7510 - val_loss: 0.6398 - val_accuracy: 0.7175\n",
      "Epoch 20/50\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.6289 - accuracy: 0.7529 - val_loss: 0.6360 - val_accuracy: 0.7262\n",
      "Epoch 21/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.6242 - accuracy: 0.7619 - val_loss: 0.6322 - val_accuracy: 0.6988\n",
      "Epoch 22/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.6194 - accuracy: 0.7576 - val_loss: 0.6280 - val_accuracy: 0.7250\n",
      "Epoch 23/50\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.6146 - accuracy: 0.7667 - val_loss: 0.6238 - val_accuracy: 0.7287\n",
      "Epoch 24/50\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.6096 - accuracy: 0.7611 - val_loss: 0.6204 - val_accuracy: 0.6975\n",
      "Epoch 25/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.6047 - accuracy: 0.7681 - val_loss: 0.6155 - val_accuracy: 0.7275\n",
      "Epoch 26/50\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.5996 - accuracy: 0.7731 - val_loss: 0.6114 - val_accuracy: 0.7212\n",
      "Epoch 27/50\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.5946 - accuracy: 0.7693 - val_loss: 0.6074 - val_accuracy: 0.7275\n",
      "Epoch 28/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.5894 - accuracy: 0.7725 - val_loss: 0.6033 - val_accuracy: 0.7275\n",
      "Epoch 29/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.5842 - accuracy: 0.7796 - val_loss: 0.5990 - val_accuracy: 0.7300\n",
      "Epoch 30/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.5791 - accuracy: 0.7764 - val_loss: 0.5950 - val_accuracy: 0.7287\n",
      "Epoch 31/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.5741 - accuracy: 0.7811 - val_loss: 0.5910 - val_accuracy: 0.7325\n",
      "Epoch 32/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.5689 - accuracy: 0.7831 - val_loss: 0.5874 - val_accuracy: 0.7337\n",
      "Epoch 33/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.5638 - accuracy: 0.7847 - val_loss: 0.5837 - val_accuracy: 0.7113\n",
      "Epoch 34/50\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.5588 - accuracy: 0.7801 - val_loss: 0.5820 - val_accuracy: 0.7050\n",
      "Epoch 35/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.5542 - accuracy: 0.7903 - val_loss: 0.5763 - val_accuracy: 0.7300\n",
      "Epoch 36/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.5494 - accuracy: 0.7914 - val_loss: 0.5725 - val_accuracy: 0.7350\n",
      "Epoch 37/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.5445 - accuracy: 0.7937 - val_loss: 0.5689 - val_accuracy: 0.7350\n",
      "Epoch 38/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.5395 - accuracy: 0.7937 - val_loss: 0.5667 - val_accuracy: 0.7212\n",
      "Epoch 39/50\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.5352 - accuracy: 0.7993 - val_loss: 0.5628 - val_accuracy: 0.7287\n",
      "Epoch 40/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.5305 - accuracy: 0.8008 - val_loss: 0.5594 - val_accuracy: 0.7300\n",
      "Epoch 41/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.5258 - accuracy: 0.8006 - val_loss: 0.5575 - val_accuracy: 0.7237\n",
      "Epoch 42/50\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.5215 - accuracy: 0.8060 - val_loss: 0.5538 - val_accuracy: 0.7325\n",
      "Epoch 43/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.5169 - accuracy: 0.8062 - val_loss: 0.5507 - val_accuracy: 0.7325\n",
      "Epoch 44/50\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.5129 - accuracy: 0.8031 - val_loss: 0.5485 - val_accuracy: 0.7262\n",
      "Epoch 45/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.5088 - accuracy: 0.8143 - val_loss: 0.5456 - val_accuracy: 0.7350\n",
      "Epoch 46/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.5045 - accuracy: 0.8099 - val_loss: 0.5430 - val_accuracy: 0.7437\n",
      "Epoch 47/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.5003 - accuracy: 0.8158 - val_loss: 0.5406 - val_accuracy: 0.7400\n",
      "Epoch 48/50\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.4967 - accuracy: 0.8179 - val_loss: 0.5385 - val_accuracy: 0.7300\n",
      "Epoch 49/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.4929 - accuracy: 0.8217 - val_loss: 0.5368 - val_accuracy: 0.7350\n",
      "Epoch 50/50\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.4889 - accuracy: 0.8233 - val_loss: 0.5341 - val_accuracy: 0.7400\n",
      "CPU times: total: 1min 7s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history_dnn = model.fit(\n",
    "    train_dataset,\n",
    "    train_dataset_labels,\n",
    "    validation_split=0.1,\n",
    "    verbose=1, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_dnn.history['val_loss']\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "#   plt.ylim([100,200])\n",
    "#   plt.xlim([100,200])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "plot_loss(history_dnn)\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 8ms/step\n",
      "   True Positive  True Negative  False Positive  False Negative\n",
      "0            612            834             162             392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72.3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_unreal = model.predict(test_dataset)\n",
    "real = np.argmax(test_predictions_unreal,axis=1)\n",
    "check=[]\n",
    "tpv=0\n",
    "fpv=0\n",
    "tnv=0\n",
    "fnv=0\n",
    "test_dataset_labels_array = test_dataset_labels.to_numpy()\n",
    "test_dataset_labels_array=[int(i) for i in test_dataset_labels_array]\n",
    "\n",
    "\n",
    "for i in range(len(test_dataset_labels_array)):\n",
    "    if test_dataset_labels_array[i]==1 and real[i]==0:\n",
    "        fnv+=1\n",
    "    elif test_dataset_labels_array[i]==0 and real[i]==1:\n",
    "        fpv+=1\n",
    "    elif test_dataset_labels_array[i]==0 and real[i]==0:\n",
    "        tnv+=1\n",
    "    elif test_dataset_labels_array[i]==1 and real[i]==1:\n",
    "        tpv+=1\n",
    "\n",
    "metrics = {\"True Positive\":[tpv],\"True Negative\":[tnv],\"False Positive\":[fpv],\"False Negative\":[fnv]}\n",
    "metrics\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df\n",
    "accuracy = (tpv+tnv)/20\n",
    "print(metrics_df)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
